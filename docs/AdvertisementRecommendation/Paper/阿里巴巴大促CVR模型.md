本文分享阿里妈妈展示广告Ranking团队针对淘宝平台电商大促周期内转化率精准预估的探索与实践。团队分析了传统转化率预估模型在电商平台大促周期内性能显著下降的现象，并定义了大促周期内转化率精准预估这个具有极大实际业务价值的问题。围绕以数据为中心的建模思路，提出了基于复用历史大促数据的Historical Data Reuse算法。HDR 考虑了三种组件，自动的数据检索出相似的大促数据，数据分布纠偏组件对比历史促销数据和目前促销状态来重新加权历史数据，Transblock模块快速的微调现有的模型来适应大促的状态。 这个HDR模型被部署在阿里的广告系统上，为展示广告大盘带来了极为显著的收益（**RPM****+9%，****CVR****+16%**）

关键词：

CVR， Label Shift， Online Advertising， Data-centric AI

## **1. 背景和难点**

促销（sales promotion） 是电商平台在**短时间内**提供**某种力度的折扣**以刺激消费者需求的一种营销策略，例如亚马逊的黑五，淘宝的双11等。 2022年淘宝一共有33次促销，占据了一年的一半时间。 CVR 模型一直是推荐系统的主要的组件， 用于预测商品的转化率信息。 但是由于大促期间的数据分布漂移， 效果良好的CVR 预测模型在大促的时候会表现的很差。如下图所示， 618 期间，AUC 和POC 出现比较大的震荡， 特别是PCOC 出现下降，双11期间，AUC会掉10%， PCOC会下降1/3。 

传统的CVR 模型对数据的假设是i.i.d.，但是数据分布出现较大波动，最直接的思路是提高模型的时效性（model freshness）。 但是CVR 和CTR 不同在于，其反馈具有一定周期，7天以上甚至更长。这种delayed feedback 造成了使用最近数据难以解决问题，并且和常规的delay feedback 考虑点不同，这里更需要考虑大促期间的数据波动的问题。 

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114135031.(null))

问题和难点List

- 大促和非大促数据分布不同，数据分布漂移导致 well-trained CVR 出现较大的效果下降
- CVR 本身的delay feedback 属性导致回收的label 时间过长，模型难以较时效的更新
- 可以使用了历史数据，但是如何从历史数据中提取和现在的大促最相似的数据，帮助现在的大促的模型更新
- 提取的历史数据和现在的分布也不一样，这个不一样对模型性能的损失如何的消除

## **2. 现有基础方法**

### 2.1 CVR

广告系统是根据eCPM实现排序和扣费的，而oCPX时代，eCPM = pCTR * pCVR * CPA，提供精准的pCTR（点击率）、pCVR（转化率）则是广告系统的重要目标。对比CTR预估，CVR预估存在三个难点

1. 样本稀疏（样本少）：转化样本一般比点击样本少1-2个数量级，正样本稀疏影响模型训练，常用的解法如多任务学习MMOE、跨域联合学习Star，甚至非目标样本融合等
2. 样本选择性偏差（SSB）：训练和预测空间不一致。正常情况下，CVR的训练为点击空间，但预测是曝光空间，因此有一些思路是把整体空间联合进行建模，例如常见解法如ESMM、DBML、ATIM等
3. 延迟反馈（回流慢）：转化行为可能在点击行为过后很久才发生，导致正样本被当作模型当作负样本使用。比如用户点击了某个商品广告，30天后才下单。假设点击后第5天，该样本进入训练数据，则会被当作负样本使用，反而影响模型对真实情况的判断（也即存在Covariate Shift）。因此，延迟反馈是当前pCVR研究的重点问题之一， 本论文描述的阿里妈妈展示广告Ranking的CVR 模型也是采用的这个思路，包括，DFM，DEFUSE等。

从模型层面缓解 Delayed Feedback 问题基本可以归为两类手段：（这个topic 往期有过分享，这里简单介绍）

1. 将Delayed Feedback看做FN（False Negative）问题，通过缩小可观测样本（包含FN样本）与真实样本（上帝全知视角）分布差异，从而预测真实 pCVR，这类手段有如下一些方法：
   1. PU（Positive-Unlabeled） Learning：与常见的通过正负样本来学习分类器不同，PU Learning通过正样本（Positive）与无标记样本（Unlabeled）来学习分类器，一般用于获取label代价较高的场景。在 Delayed Feedback 场景，label=0的样本中包含正样本与负样本，因此统一视为无标记样本
   2. Importance Sampling：Importance Sampling是一种通过在A分布样本（可观测样本）进行采样，预估B分布样本（真实样本）上统计量的手段
2. 延迟转化问题，本质两个问题：是否延迟、是否转化，因此可以作为一个多目标问题建模。而具体如何拆解这两个目标，下文列举一些方案：
   1. 将延迟转化问题拆解为“是否转化，第几天转化”多目标建模，代表论文为Criteo的“Modeling Delayed Feedback in Display Advertising”，为Google的“Handling many conversions per click in modeling delayed feedback”
   2. 将延迟建模问题，结合样本回补机制以及延迟样本纠偏的方式形成的方法，包括DFM、DEFUSE（Asymptotically Unbiased Estimation for Delayed Feedback Modeling via Label Correction）

例如DEFUSE

1. 将目标拆分为四个类别，利用窗口内的观测到样本以及引入窗口外完整的验证正样本信息进行建模（区别ES-DFM 的样本处理）
2. 对分别表示基于完整归因周期的真实(ground-truth)分布和基于观测窗口与引入样本回补的观测(observed)分布进行IS的纠偏。
3. 在1中四个类别建模的情况下，（窗口内的真负和假负，RN与FN）无法通过观测数据直接区分。为了解决这一问题引入隐变量Z来进行建模。

两个塔使用的训练样本是不一致的。对于Inw Data的塔，使用的是非重复的正确样本，面向真实分布建模，对于Outw Data塔，采用和FNW一样的样本回补机制（如下图b的第3行），损失函数由这两个塔的loss相加形成，如下

$$P(y=1|x) = F_{IP}(X) + F_{DP}(X) \\ $$

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131659.(null))

 

### 2.2 Distribution Shift

促销期间实际CVR的波动主要是数据分布漂移造成。 而根据贝叶斯公式， p(x|y) * p(y) = p(y|x) * p(x)  其中有三个我们可以考虑的概率分布项：输入空间的边缘概率分布p(x) , 输出空间的标签分布 p(y) ，以及表示该机器学习任务的条件概率分布 p(y|x) 。当源域和目标域的三者之一发生了变化，我们都认为发生了源域与目标域的数据集的分布发生了偏移，即 **数据集偏移 dataset bias**。 

常见的漂移包括三种， 协变量漂移（covariate shift)， 标签漂移(label shift)， 概念漂移(concept shift)

- 协变量漂移： 分类函数固定P(Y|X) 固定，只有协变量P(X) 发生变化
- 标签漂移：条件分布P(X|Y)固定，只有标签分布P(Y)随着数据域发生变化，则算做发生了标签漂移。
- 概念漂移： 都变化了（ 这种一般不做解决，常规论文也处理的上述的两种情况）

另外还有一个概念叫做domain shift，这个概念也有很多论文，大概的是处理比如迁移学习这个topic里面的，包括图像里面的一些预训练之后应用在不同域test 数据上造成的漂移的处理。

对于协变量漂移，常规的处理方法都是基于样本重要性（ importance weights ），例如Importance-Weighted Empirical Risk Minimization (IW-ERM) 这个方法。 对于标签漂移，有一些方法比如Black Box Shift Estimation(BBSE)， 另外还有一些因果推断的解决方案去debias角度，比如Regularized Learning under Label Shift (RLLS)。 这篇论文是基于[Black Box Shift Estimation](https://arxiv.org/pdf/1802.03916.pdf)(BBSE) 和RLLS 的一些结论进行利用。

## **3. 解决方案**

现有的CVR 模型的训练模式

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131004.(null))

常规的训练机制形式化描述

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114130629.(null))

基于B 的数据上进行FineTune 的更新模型参数，但是大促模型的数据和之前数据不具有IID 的关系。所以用之前数据训练的模型肯定会出现较大的偏差。

因此方案就围绕以下三个问题。

1. 如何去获取和现在大促数据分布相同的历史的促销数据
2. 如何去处理两份数据的差异
3. 如何更有效率架构的在这份历史数据上去微调

### **3.1 获取相似数据**

设计了有效率的Vector-Based 的方式来获得相似的历史促销数据。在大促系统中，历史数据以自然天的方式分区， 因此我们我们把每天作为一个单位来作为候选集。 大促具有一定的模式特别在转化率上，随着时间呈现，大促前抑制，大促中激增，大促后恢复。为此，在计算数据相似度时，采用了最近三天的两种转化相关特征。

 

- CVRs from previous days

每天的平均 CVR 显然是不同转换模式的良好指标。我们首先采用最近三天向量的一组 CVR 指标 表示。生产系统使用三天作为归因窗口

- Impression ratio of representative categories

实践中发现，大促期间某些类别的产品会出现曝光率增加，购买量也随着增加，比如化妆品。

因此，我们考虑了这样的几个代表性类别，并利用每个类别的印象比作为一个数字特征。在这里，一个类别的曝光比是用给定类别的曝光数除以曝光数来计算的。同时，根据促销时段和非促销时段的展示比差异来选择这些类别，包括幼儿，房屋清洁，个人护理，化妆品等。因此，我们利用目标推广日的前10个小时的数据进一步计算展示比。这些新特性提高了数据检索的性能，并进一步提高了在线性能，尽管模型服务会延迟10个小时

 

然后基于上述的特征形成Vector 的表示，使用余弦相似度进行计算召回。距离最近的的top-two数据会被召回出来。

### **3.2 分布漂移纠偏**

获得了上述的的历史数据之后，历史大促和现在大促的数据也存在较大的分布差异， 目前已知的数据是原始的历史大促X，历史大促的标签Y，现在大促的特征X。$$B'(x,y)$$ 表示历史大促数据的分布，$$B(x,y)$$ 表示目标大促数据的分布。 我们的目标是纠偏，利用样本权重的思路进行纠偏， Importance-Weighted Empirical Risk Minimization 

$$L = \int \frac{\mathcal B(x,y)}{\mathcal B'(x,y)} \cdot \ell (x,y) d \mathcal B'(x,y)$$

$$\frac{B(x,y)}{B'(x,y)} \cdot B'(x,y)$$  表示两个分布的权重差异的样本加权

进一步推导可变成

$$L= \int \frac{\mathcal B(x|y)}{\mathcal B'(x|y)} \cdot\frac{\mathcal B(y)}{\mathcal B'(y)} \cdot \ell (x,y) d \mathcal B'(x,y)$$

到这里计算两份数据的纠偏差异的时候，采用了近似的方法，设定了两个假设。

有两个假设

**假设1** 

假设满足label shift 的， 后验分布相等。根据对数据进行统计计算，如Table1 中所示的数据，可以看到y=1 购买行为下，协变量的分布基本是相同的，这里简单用两个变量U 和C来分析。

$$\mathcal B(x|y) = \mathcal B'(x|y)$$

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114130964.(null))

**假设2**

假设两份数据的比例差异是稳定的，小时的数据之间的差异和天级之间的差异是稳定近似相等的。 那么我们在计算两份数据的label 差异的时候，就可以让模型delay h 个小时，从而可以计算两份数据的label 的差异，实际设置中，设置h=10， 因此模型serving delay 10 个小时。

$$\frac{\mathcal B(y)}{\mathcal B'(y)} = \frac{\mathcal B_h(y)}{\mathcal B_h'(y)} $$

$$B_h(y)$$ 表示从0点到h 时间的数据的label 分布。

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114130939.(null))

$$\begin{aligned} \mathcal L &= \int \frac{\mathcal B(x,y)}{\mathcal B'(x,y)} \cdot \ell (x,y) d \mathcal B'(x,y) \\ & = \int \frac{\mathcal B(x|y)}{\mathcal B'(x|y)} \cdot\frac{\mathcal B(y)}{\mathcal B'(y)} \cdot \ell (x,y) d \mathcal B'(x,y) \\ & = \int \frac{\mathcal B(y)}{\mathcal B'(y)} \cdot \ell (x,y) d \mathcal B'(x,y) \\ &= \int \frac{\mathcal B_h(y)}{\mathcal B_h'(y)} \cdot \ell (x,y) d \mathcal B'(x,y) \\ \end{aligned}$$

两份分布的差异就近似的变为了两份label分布在h 小时真实数据的差异。

### **3.3 纠偏 With TransBlock**

遇到了overfitting 的问题。 也就是两次同样数据在模型中重复训练造成的过拟合的问题。

TransBlock 在主模型上引入了堆叠在主模型上额外的参数，在微调的时候，TransBlock 和主模型的参数会被同时的从召回历史数据中更新。为了从同一份数据中重训练造成的避免过拟合的问题，这时候对主模型**设置很小的学习率**

这样主模型从非促销的数据中学习的模型参数会很少的影响。

TransBlock 是建模从非大促转化 到大促转化之间的变化

为了捕捉非促销转化和促销转化的差异，以三个组件来学习促销转化的概率。

- 从主模型中获得的非大促的转化率
- 大促转化 来自于 非大促不转化 
- 大促不转化 来自于 非大促转化

整体转化 = 非促销转化 + 促销转化 - 促销非转化

$$\begin{aligned} P_t(y=1|x) &= P(y=1|x) + v_x * p(y=0|x) - u_x* p(y=1|x) \\ &=  P(y=1|x)  + (v_x + u_x) * p(y=0|x) - u_x \\ &=  P(y=1|x)  + w_x * p(y=0|x) - b_x \end{aligned}$$

实际上，这个TransBlock 就是一个简单的MLP 的网络结构，以主模型的非大促转化预估作为输入， 以及在embedding 之后的x 作为输入特征，h_x。 按上述的公式计算最后的输出。

由于TransBlock 的输出为三部分的和，不保障输出区间在0-1 范围内，因此进行了[0-1] 的截断处理。

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131527.(null))

#### 附加 topic- **One Epoch Problem**

https://zhuanlan.zhihu.com/p/575431397

在训练的第一个epoch结束，第二个epoch开始时，预估模型发生过拟合现象，并且在测试集上的效果急剧下降，我们称其为“one epoch现象”。为了解释该现象，我们在工业生产数据集上进行了大量实验。结果显示模型结构、模型的快速收敛（例如强优化器和较大学习率）以及特征ID的稀疏性是导致one epoch现象的关键因素。令人惊讶的是，深度模型往往在训练一个epoch后就可以达到最佳性能，这也解释了为什么许多工业推荐系统只对数据进行一次训练.

CV（计算机视觉）和NLP（自然语言处理）领域的深度学习模型通常需要训练几十个上百个epochs才能达到最优，如果发生过拟合现象，也往往是在训练过程中逐步发生。但在推荐系统中却并非如此，我们在阿里巴巴展示广告的生产环境下，将CTR模型训练3个epoch，得到的测试AUC曲线如下：

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131891.(null))

one-epoch现象与特征稀疏性 使用三种方法(1) 过滤（filter），过滤掉出现频率最低的ID，将他们替换为默认值；(2) 哈希（hash），使用较小的哈希表来对每个ID做映射；(3) 不使用稀疏性强的特征域，例如不使用item_ID和history_item_IDs这两个特征域

上述三种方法都可以缓解甚至消除one-epoch现象，但都会存在一定的精度损失。这表明特征稀疏性与one-epoch现象密切相关，同时这也可以解释为什么部分场景训练的CTR模型不会遇到one-epoch现象——如果只用粗粒度特征或者采用过滤/哈希的方式降低了数据稀疏性，模型是可以训练多个epoch的。

### **3.4 整体的架构**

HDR 设计了一种新的基于历史数据召回的微调和正常模型训练一起的架构。最底部主模型每天例行的基础更新，另外的微调模型重新加载主模型参数并初始化TraskBlock 的参数， 一但召回模块数据ready了，微调模型自动的调用。 微调模块也是天级别更新。

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131733.(null))

## **4. 实验结论分析**

### **4.1 观测指标**

|                          | 具体指标           |      |
| ------------------------ | ------------------ | ---- |
| Ranking Performance      | AUC                |      |
| Callibration Performance | LogLoss，PCOC，ECE |      |

- *PCOC*是校准之后的点击率与后验点击率（近似真实概率）的比值，越接近于1，意味着在绝对值上越准确，大于1为高估，小于1为低估，是一种常用的高低估评价*指标*。
- ECE是期望校准误差，基于预测结果将数据分为多个桶，然后再每个桶里面计算分桶正确的数据比例。

具体公式为：

$$ECE = \sum_{b=1}^B \frac{n_b}{N}|acc(b) - conf(b)|$$

acc表示真实平均值，conf 表示预测的平均值

在模型的离线评测上，我们使用常见的AUC指标来评价模型的排序能力；使用PCOC，LogLoss以及ECE来评价模型的预估准度，其中PCOC越接近1，LogLoss以及ECE越低，代表模型的预估准度越好；

在模型的在线评测上，我们根据日常迭代的经验，用在线AUC以及PCOC来评测模型的预估性能；同时，我们用广告系统的业务指标RPM、CVR、ROI来评价模型实际带来的业务收益；CVR自不必多说，而RPM是广告系统的核心指标，代表每千次广告展现给平台带来的收入；ROI代表投入产出比，代表广告引导的成交金额与广告主投入的广告费的比值，正相关于客户体验。

### **4.2 评测结果**

- Base：阿里妈妈展示广告生产模型DEFER，是一种基于延迟反馈建模的流式训练方案；
- ES-DFM、DEFUSE：其他经典的延迟反馈建模方案；
- Base w/o DFM：去除补偿样本机制的的DEFER模型；
- Base w/ promotion indicator：除了利用历史大促数据进行微调之外，另一种可能的可行方法是在输入中加入指示当前是大促还是非大促的特征。通过这种方式，模型有可能可以学习大促和非大促转化模式的不同。因此我们将其作为待对比的基线之一；
- Base w/ direct retraining：最简单的数据重用方法是直接在检索到的历史数据上重新训练一次生产模型。实际上，这种方法等同于智能数据复用去掉了分布纠偏模块和TransBlock模块。然而，这可能会引入所谓的“One-Epoch”问题，我们也将它列为对比方法之一。

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131880.(null))

#### 4.2.1 实验结果解释分析

Base 的模型效果是最差的，AUC =0.793， PCOC= 0.471 。这个结果符合上述问题描述的现有CVR模型对大促效果下降，也证明了是需要对大促进行模型优化的。

我们进一步研究了不同延迟反馈建模方案的有效性。根据表1所示，我们发现所有的延迟反馈模型（ES-DFM和DEFUSE）的表现都与Base一样糟糕。相反，在移除延迟反馈模块后（即 Base w/o DFM），模型表现显著优于之前：尽管PCOC指标仍然较低，但AUC和ECE等指标均大幅变优。这直接论证了大促周期内延迟反馈模型的基础假设的不成立。

除此之外，我们也对另外两种可能的方案进行了简单实验，即Base w/ promotion indicator和 Base w/ direct retraining。同样地，从实验结果我们可以发现，它们都没能获得更好的效果。Base w/ promotion indicator大促/非大促特征的引入并没有多大帮助，这可能是由于**在连续的学习中遗忘了以前的大促转化模式**。同时，直接复用历史数据进行训练也未能取得好效果：**AUC****甚至下降了2.8%。我们认为其主要原因是数据的二次训练导致了****过拟合****问题。这也再次证明了探索更合适的历史数据复用机制的必要性**。

我们提出的智能数据复用（HDR）算法就提供了这样的机制。如下表中所示，HDR在排序能力和预估准度方面均显著优于所有其他方法：AUC上优于Base方法10.3%，而PCOC为0.99，几乎达到了理想值1.0。同时，它也在Logloss和ECE指标上获得了最佳表现，这些结果充分证明了HDR的有效性。

### **4.3 消融分析**

由于大促CVR精准预估问题是第一次被提出，没有相关的公开数据集可使用。因此，我们直接在阿里妈妈展示广告平台的生产数据集上进行了分析实验。我们选取了几类具有代表性的基线方法：

- Base：阿里妈妈展示广告生产模型DEFER，是一种基于延迟反馈建模的流式训练方案；
- ES-DFM、DEFUSE：其他经典的延迟反馈建模方案；
- Base w/o DFM：去除延迟反馈建模的DEFER模型；
- Base w/ promotion indicator：除了利用历史大促数据进行微调之外，另一种可能的可行方法是在输入中加入指示当前是大促还是非大促的特征。通过这种方式，模型有可能可以学习大促和非大促转化模式的不同。因此我们将其作为待对比的基线之一；
- Base w/ direct retraining：最简单的数据重用方法是直接在检索到的历史数据上重新训练一次生产模型。实际上，这种方法等同于智能数据复用去掉了分布纠偏模块和TransBlock模块。然而，这可能会引入所谓的“One-Epoch”问题，我们也将它列为对比方法之一。

#### 4.3.1 Distribution Shift Correction的影响

为了了解分布纠偏（DSC，3.2.2章所述）的影响，我们进行了移除DSC的实验（即HDR w/o DSC）如表1所示，我们获得了与完整HDR方法几乎相同的AUC，这证明了复用历史数据已经能够带来模型排序能力上的巨大提升。不过预估准度下降了很多：PCOC仅为0.803，ECE也大幅增加（ECE越低越好）。这说明了DSC模块对于预估准度的重要性。

#### 4.3.2 TransBlock的影响.

同时，我们也进行了移除TransBlock模块（即HDR w/o TransBlock）的实验。与HDR相比，我们发现模型性能因为过拟合而显著下降了，**这证明了TransBlock对于历史数据复用机制的必要性。**

#### 4.3.3检索效果的影响

在表3中，我们提供了几个真实检索结果来更好地展现数据检索的效果。第一个是查找与99大促相似的促销。我们检索到的前两个日期是2022年8月8日的88大促，以及2022年6月14日的618大促二峰，CVR也都比较接近。第二个例子是寻找与88促销相似的促销。我们检索到的Top2结果是2022年7月12日的狂暑季大促，以及7月31日的七夕节大促（没有检索到99大促是因为88大促发生在99大促之前）。同时，我们还随机展示了一个低相似度的非大促日期。显然，这个随机日期的整体CVR与目标大促日期相差很大。

![img](阿里巴巴大促CVR模型.assets/(null)-20230908114131939.(null))

### **4.4 生产部署**

HDR 部署在阿里展示广告的系统上，服务于2022年双11的大促。

在历史数据获取阶段， 创建了一个map-reduce 任务对每天建立了一个vector 标识的索引，然后计算每天和今天的相似度。选择最近的两天来作为微调模型。由于这个vector-representation 用了一天的前10个小时作为特征，因此这个过程在每天早上10:30 完成。

在微调的阶段，为这个损失函数计算重要性权重 . 分母是直接从历史数据中计算出，分子可以从上述的公式中计算出，利用两个和 。 前者利用解析的实时预测数据流，后者利用现有模型预测历史数据。

微调的阶段在11:00 的时候完成。

## **5. 总结和讨论**

智能数据复用方案的一个潜在问题是历史数据的重用可能受到数据过时的影响。具体而言，在线广告系统是动态的，因为活跃的广告主和广告活动不断变化，因此不同周期的活跃广告可能会有显著差异。在过时的历史数据上进行微调的模型可能不是最优的，甚至对在线性能有害。然而，在实践中，我们没有观察到任何适得其反的表现。**这可能归因于微调机制的设计，其中原始模型由于学习率小而很少更新**，而TransBlock(仅使用少数参数)学习粗粒度知识，例如分类水平差异，用于数据适应。这种现象值得我们进一步探索，以更好地理解历史数据的使用机制，我们将在未来考虑到这一点。

## 参考文献

[1] Yang, Jia-Qi and Li, Xiang and Han, Shuguang and Zhuang, Tao and Zhan, De-Chuan and Zeng, Xiaoyi and Tong, Bin. [Capturing delayed feedback in conversion rate prediction via elapsed-time sampling](https://arxiv.org/pdf/2305.12837.pdf). AAAI 2021